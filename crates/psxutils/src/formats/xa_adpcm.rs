//! XA-ADPCM (Adaptive Differential Pulse Code Modulation) decoder.
//!
//! Based on jPSXdec implementation by Michael Sabin.
//! References:
//! - `jpsxdec/src/jpsxdec/adpcm/SoundUnitDecoder.java`
//! - `jpsxdec/src/jpsxdec/adpcm/K0K1Filter.java`
//! - `jpsxdec/src/jpsxdec/adpcm/XaAdpcmDecoder.java`

/// Number of sound groups per XA audio sector
pub const SOUND_GROUPS_PER_SECTOR: usize = 18;

/// Size of each sound group in bytes
pub const SOUND_GROUP_SIZE: usize = 128;

/// Number of PCM samples generated per sound unit
pub const SAMPLES_PER_SOUND_UNIT: usize = 28;

/// Number of sound units in 4-bit sound group
pub const SOUND_UNITS_4BIT: usize = 8;

/// Number of sound units in 8-bit sound group
pub const SOUND_UNITS_8BIT: usize = 4;

/// K0 filter coefficients for XA-ADPCM
const K0_FILTERS: [f64; 4] = [
    0.0,      // Filter 0
    0.9375,   // Filter 1:  60.0 / 64.0
    1.796875, // Filter 2: 115.0 / 64.0
    1.53125,  // Filter 3:  98.0 / 64.0
];

/// K1 filter coefficients for XA-ADPCM
const K1_FILTERS: [f64; 4] = [
    0.0,       // Filter 0
    0.0,       // Filter 1
    -0.8125,   // Filter 2: -52.0 / 64.0
    -0.859375, // Filter 3: -55.0 / 64.0
];

/// ADPCM decoding context (maintains state between samples)
#[derive(Debug, Clone)]
struct AdpcmContext {
    /// Previous PCM sample (t-1)
    prev1: f64,
    /// Previous-previous PCM sample (t-2)
    prev2: f64,
    /// Volume scale factor
    volume: f64,
}

impl AdpcmContext {
    fn new(volume: f64) -> Self {
        Self {
            prev1: 0.0,
            prev2: 0.0,
            volume,
        }
    }

    /// Decode, scale, round, clamp, and save a PCM sample
    fn process_sample(&mut self, decoded: f64) -> i16 {
        // Scale by volume
        let scaled = decoded * self.volume;

        // Round to nearest integer
        let rounded = scaled.round();

        // Clamp to 16-bit range
        let clamped = rounded.clamp(-32768.0, 32767.0) as i16;

        // Save for next samples
        self.prev2 = self.prev1;
        self.prev1 = clamped as f64;

        clamped
    }
}

/// XA-ADPCM decoder
pub struct XaAdpcmDecoder {
    /// Is stereo (true) or mono (false)
    stereo: bool,
    /// Bits per sample (4 or 8)
    bits_per_sample: u8,
    /// Left channel context (or mono)
    left_context: AdpcmContext,
    /// Right channel context (if stereo)
    right_context: Option<AdpcmContext>,
}

impl XaAdpcmDecoder {
    /// Create a new XA-ADPCM decoder
    ///
    /// # Arguments
    /// * `bits_per_sample` - Either 4 or 8
    /// * `stereo` - true for stereo, false for mono
    /// * `volume` - Volume scale factor (1.0 = normal)
    pub fn new(bits_per_sample: u8, stereo: bool, volume: f64) -> Self {
        assert!(
            bits_per_sample == 4 || bits_per_sample == 8,
            "bits_per_sample must be 4 or 8"
        );

        Self {
            stereo,
            bits_per_sample,
            left_context: AdpcmContext::new(volume),
            right_context: if stereo {
                Some(AdpcmContext::new(volume))
            } else {
                None
            },
        }
    }

    /// Calculate number of PCM sample frames generated by one sector
    ///
    /// A "frame" is one sample for mono, or one sample per channel for stereo.
    pub fn samples_per_sector(&self) -> usize {
        let sound_units = match self.bits_per_sample {
            4 => SOUND_UNITS_4BIT,
            8 => SOUND_UNITS_8BIT,
            _ => unreachable!(),
        };

        SOUND_GROUPS_PER_SECTOR * SAMPLES_PER_SOUND_UNIT * sound_units
            / if self.stereo { 2 } else { 1 }
    }

    /// Decode one XA audio sector to PCM samples
    ///
    /// # Arguments
    /// * `sector_data` - Raw sector data (should be 2324 bytes for MODE2FORM2)
    ///
    /// # Returns
    /// Vector of interleaved PCM samples (i16).
    /// For stereo: [L, R, L, R, ...]
    /// For mono: [M, M, M, ...]
    pub fn decode_sector(&mut self, sector_data: &[u8]) -> Vec<i16> {
        let mut output = Vec::new();

        // Each sector has 18 sound groups
        for sound_group_idx in 0..SOUND_GROUPS_PER_SECTOR {
            let group_offset = sound_group_idx * SOUND_GROUP_SIZE;

            if group_offset + SOUND_GROUP_SIZE > sector_data.len() {
                break; // Incomplete group
            }

            let sound_group = &sector_data[group_offset..group_offset + SOUND_GROUP_SIZE];

            // Decode this sound group
            self.decode_sound_group(sound_group, &mut output);
        }

        output
    }

    /// Decode one sound group (128 bytes)
    fn decode_sound_group(&mut self, sound_group: &[u8], output: &mut Vec<i16>) {
        let sound_units = match self.bits_per_sample {
            4 => SOUND_UNITS_4BIT,
            8 => SOUND_UNITS_8BIT,
            _ => unreachable!(),
        };

        // Decode each sound unit
        for unit_idx in 0..sound_units {
            // Extract sound parameters (first 16 bytes of sound group)
            let params = &sound_group[0..16];

            // Decode sound unit data
            let pcm_samples = self.decode_sound_unit(sound_group, unit_idx, params);

            // For stereo, odd units go to right channel, even to left
            if self.stereo {
                let is_right_channel = unit_idx % 2 == 1;

                if is_right_channel {
                    // Interleave: output should already have left samples, add right
                    let left_offset = output.len() - SAMPLES_PER_SOUND_UNIT;
                    for i in 0..SAMPLES_PER_SOUND_UNIT {
                        output.insert(left_offset + i * 2 + 1, pcm_samples[i]);
                    }
                } else {
                    // Add left channel samples (will be interleaved when right comes)
                    output.extend_from_slice(&pcm_samples);
                }
            } else {
                // Mono: just append
                output.extend_from_slice(&pcm_samples);
            }
        }
    }

    /// Decode one sound unit (28 samples)
    fn decode_sound_unit(
        &mut self,
        sound_group: &[u8],
        unit_idx: usize,
        params: &[u8],
    ) -> [i16; SAMPLES_PER_SOUND_UNIT] {
        let mut pcm_out = [0i16; SAMPLES_PER_SOUND_UNIT];

        // Get sound parameters for this unit
        let (filter_idx, range) = self.get_sound_parameters(params, unit_idx);

        // Extract all ADPCM samples first (before borrowing context)
        let mut adpcm_samples = [0i16; SAMPLES_PER_SOUND_UNIT];
        for sample_idx in 0..SAMPLES_PER_SOUND_UNIT {
            adpcm_samples[sample_idx] = self.get_adpcm_sample(sound_group, unit_idx, sample_idx);
        }

        // Choose context based on channel (for stereo)
        let context = if self.stereo && unit_idx % 2 == 1 {
            self.right_context.as_mut().unwrap()
        } else {
            &mut self.left_context
        };

        // Decode 28 samples
        for sample_idx in 0..SAMPLES_PER_SOUND_UNIT {
            let adpcm_sample = adpcm_samples[sample_idx];

            // Shift according to range (arithmetic right shift to extend sign)
            let unranged = (adpcm_sample as i32) >> range;

            // Apply K0/K1 filters
            let filtered = unranged as f64
                + K0_FILTERS[filter_idx] * context.prev1
                + K1_FILTERS[filter_idx] * context.prev2;

            // Scale, round, clamp, and save
            pcm_out[sample_idx] = context.process_sample(filtered);
        }

        pcm_out
    }

    /// Extract sound parameters (filter index and range) for a sound unit
    fn get_sound_parameters(&self, params: &[u8], unit_idx: usize) -> (usize, u8) {
        // Sound parameters are stored in first 16 bytes
        // For 4-bit: parameters are duplicated and interleaved
        // For 8-bit: parameters are repeated 4 times

        let param_byte = if self.bits_per_sample == 4 {
            // 4-bit: 8 units, params at [0..4] and [4..8] (duplicated)
            params[unit_idx % 4]
        } else {
            // 8-bit: 4 units, params at [0..4] repeated
            params[unit_idx]
        };

        let filter_idx = ((param_byte & 0x0C) >> 2) as usize & 0x03;
        let range = (param_byte & 0x0F).min(12); // Clamp to max 12

        (filter_idx, range)
    }

    /// Extract one ADPCM sample from sound group
    fn get_adpcm_sample(&self, sound_group: &[u8], unit_idx: usize, sample_idx: usize) -> i16 {
        // ADPCM data starts after the 16-byte parameter header
        let data_offset = 16;

        if self.bits_per_sample == 4 {
            // 4-bit samples: 2 samples per byte
            // Sound units are interleaved
            let byte_idx = data_offset + sample_idx * 4 + unit_idx / 2;
            let byte = sound_group[byte_idx] as i16;

            // Even units use high nibble, odd units use low nibble
            let nibble = if unit_idx % 2 == 0 {
                (byte >> 4) & 0x0F
            } else {
                byte & 0x0F
            };

            // Sign-extend 4-bit to 16-bit (shift to top, then arithmetic shift back)
            (nibble << 12) >> 4
        } else {
            // 8-bit samples: 1 sample per byte
            let byte_idx = data_offset + sample_idx * 4 + unit_idx;
            let byte = sound_group[byte_idx] as i8 as i16;

            // Sign-extend 8-bit to 16-bit (shift to top, then arithmetic shift back)
            (byte << 8) >> 4
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_decoder_creation() {
        let decoder = XaAdpcmDecoder::new(4, true, 1.0);
        assert_eq!(decoder.samples_per_sector(), 18 * 28 * 8 / 2);

        let decoder = XaAdpcmDecoder::new(8, false, 1.0);
        assert_eq!(decoder.samples_per_sector(), 18 * 28 * 4);
    }

    #[test]
    fn test_filter_coefficients() {
        // Verify XA filter coefficients
        assert_eq!(K0_FILTERS[0], 0.0);
        assert_eq!(K0_FILTERS[1], 0.9375);
        assert_eq!(K1_FILTERS[2], -0.8125);
        assert_eq!(K1_FILTERS[3], -0.859375);
    }
}
